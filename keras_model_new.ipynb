{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_model_new.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wxya2017/GR5242-CIFAR10/blob/master/keras_model_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "NqySGebkCKkC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m7VOZ-TkCPzJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2380ca42-e281-40f5-9ca1-0fafb529d151"
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "# 指定当前的工作目录\n",
        "import os\n",
        "os.chdir(\"drive/5242\") "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fuse: mountpoint is not empty\n",
            "fuse: if you are sure this is safe, use the 'nonempty' mount option\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NrLb96P4CTnv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "0c9ed567-32a5-46ff-e8db-f7d47050eb3e"
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cross_validation import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import tensorflow as tf\n",
        "# from tensorflow.python.eager import context\n",
        "\n",
        "import keras\n",
        "# from tensorflow.keras.models import Sequential, load_model\n",
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "# from tensorflow.train import AdamOptimizer\n",
        "# from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "# from tensorflow.keras import regularizers, optimizers\n",
        "# from tensorflow.keras.callbacks import TensorBoard\n",
        "# from tensorflow.keras import regularizers, optimizers\n",
        "import time\n",
        "\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from keras import regularizers, optimizers\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras import regularizers, optimizers\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
            "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "vAtl2Zl5CgDo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "class TrainValTensorBoard(TensorBoard):\n",
        "    def __init__(self, log_dir='./logs', **kwargs):\n",
        "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
        "        training_log_dir = os.path.join(log_dir, 'training')\n",
        "        super(TrainValTensorBoard, self).__init__(training_log_dir, **kwargs)\n",
        "\n",
        "        # Log the validation metrics to a separate subdirectory\n",
        "        self.val_log_dir = os.path.join(log_dir, 'validation')\n",
        "\n",
        "    def set_model(self, model):\n",
        "        # Setup writer for validation metrics\n",
        "        self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
        "        super(TrainValTensorBoard, self).set_model(model)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Pop the validation logs and handle them separately with\n",
        "        # `self.val_writer`. Also rename the keys so that they can\n",
        "        # be plotted on the same figure with the training metrics\n",
        "        logs = logs or {}\n",
        "        val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
        "        for name, value in val_logs.items():\n",
        "            summary = tf.Summary()\n",
        "            summary_value = summary.value.add()\n",
        "            summary_value.simple_value = value.item()\n",
        "            summary_value.tag = name\n",
        "            self.val_writer.add_summary(summary, epoch)\n",
        "        self.val_writer.flush()\n",
        "\n",
        "        # Pass the remaining logs to `TensorBoard.on_epoch_end`\n",
        "        logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
        "        super(TrainValTensorBoard, self).on_epoch_end(epoch, logs)\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        super(TrainValTensorBoard, self).on_train_end(logs)\n",
        "        self.val_writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yes5q0LvCioh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Run Tensorflow in the background - note that we specify the log \n",
        "# directory we want to look at\n",
        "LOG_DIR = 'logs_keras_new'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o0TFtxxgOl5t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24d462ad-f7ab-471a-84e1-a4029edf1828"
      },
      "cell_type": "code",
      "source": [
        "# Launch the ngrok background process\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "# Get the public URL and be sorted!\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c\\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://2f89cd79.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nJN3LnP3C1vQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "\n",
        "\n",
        "def load_data(dir):\n",
        "    train_x = np.array(unpickle(dir+'data_batch_1')[b'data'])\n",
        "    train_y = np.array(unpickle(dir+'data_batch_1')[b'labels'])\n",
        "    for i in range(2,6):\n",
        "        train_x = np.concatenate((train_x, np.array(unpickle(dir+'data_batch_'+str(i))[b'data'])), axis = 0)\n",
        "        train_y = np.concatenate((train_y, np.array(unpickle(dir+'data_batch_'+str(i))[b'labels'])),axis = 0)\n",
        "\n",
        "\n",
        "    test_x = np.array(unpickle(dir+'test_batch')[b'data'])\n",
        "    test_y = np.array(unpickle(dir+'test_batch')[b'labels'])   \n",
        "    labels = unpickle(dir+'batches.meta')[b'label_names']\n",
        "    return train_x, train_y, test_x, test_y, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oP8XMfOKCxuz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reshape(image):\n",
        "    out = np.zeros(shape=[32,32,3])\n",
        "    for i in range(3):\n",
        "        out[:,:,i] = image[1024*i:1024*(i+1)].reshape([32,32])\n",
        "    return out\n",
        "\n",
        "def pre_process_x(x):\n",
        "    new_x = np.zeros(shape=[len(x),32,32,3])\n",
        "    for i in range(len(x)):\n",
        "        new_x[i] = reshape(x[i])\n",
        "    new_x = new_x/255\n",
        "    return new_x\n",
        "\n",
        "def pre_process_y(y):\n",
        "    new_y = np.zeros([len(y),10])\n",
        "    for i in range(len(y)):\n",
        "        new_y[i][y[i]-1] = 1\n",
        "    return new_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C69vCKS3C8SL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Functions for plots\n",
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1, 2,figsize=(10, 5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
        "    axs[0].legend(['train', 'validation'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'validation'], loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Po2A6twfDAD3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "a5260434-a104-4865-e4ac-883fdde6a3e0"
      },
      "cell_type": "code",
      "source": [
        "ori_train_x, ori_train_y, ori_test_x, ori_test_y, labels = load_data('data/')\n",
        "\n",
        "train_x = pre_process_x(ori_train_x)\n",
        "test_x = pre_process_x(ori_test_x)\n",
        "train_y = pre_process_y(ori_train_y)\n",
        "test_y = pre_process_y(ori_test_y)\n",
        "print(\"===>training data shape is \"+ str(train_x.shape))\n",
        "print(\"===>test data shape is \"+ str(test_x.shape))\n",
        "print(\"===>training label shape is \"+ str(train_y.shape))\n",
        "print(\"===>test label shape is \"+ str(test_y.shape))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===>training data shape is (50000, 32, 32, 3)\n",
            "===>test data shape is (10000, 32, 32, 3)\n",
            "===>training label shape is (50000, 10)\n",
            "===>test label shape is (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ldRZwxJSDC-l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QT7lkcyiIxN1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# baseline"
      ]
    },
    {
      "metadata": {
        "id": "l1BzLs7QDGSc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_model_base(num_classes = 10, baseMapNum = 32):\n",
        "    '''build weight decay model'''\n",
        "    model_base = Sequential()\n",
        "    model_base.add(Conv2D(baseMapNum, (3,3), name='conv1', padding='same', kernel_regularizer=regularizers.l2(1e-4), input_shape=train_x.shape[1:]))\n",
        "    model_base.add(Activation('relu', name='relu1'))\n",
        "    \n",
        "    model_base.add(Conv2D(baseMapNum, (3,3), name='conv2', padding='same', kernel_regularizer=regularizers.l2(1e-4)))\n",
        "    model_base.add(Activation('relu', name='relu2'))\n",
        "    model_base.add(MaxPooling2D(pool_size=(2,2), name='maxp1'))\n",
        "    model_base.add(Dropout(0.5, name='drop1'))\n",
        "    \n",
        "    model_base.add(Conv2D(2*baseMapNum, (3,3), name='conv3', padding='same', kernel_regularizer=regularizers.l2(1e-4)))\n",
        "    model_base.add(Activation('relu', name='relu3'))\n",
        "    \n",
        "    model_base.add(Conv2D(2*baseMapNum, (3,3), name='conv4', padding='same', kernel_regularizer=regularizers.l2(1e-4)))\n",
        "    model_base.add(Activation('relu', name='relu4'))\n",
        "    model_base.add(MaxPooling2D(pool_size=(2,2), name='maxp2'))\n",
        "    model_base.add(Dropout(0.3, name='drop2'))\n",
        "\n",
        "\n",
        "    model_base.add(Flatten())\n",
        "    model_base.add(Dense(num_classes, activation='softmax', name='dense'))\n",
        "    \n",
        "    model_base.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) \n",
        "    return model_base\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lgf1wWDpDHHs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "outputId": "b9cd00dc-5994-4c58-bc66-15f22cc3c507"
      },
      "cell_type": "code",
      "source": [
        "model_base = build_model_base()\n",
        "print(model_base.summary())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "relu1 (Activation)           (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "relu2 (Activation)           (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "maxp1 (MaxPooling2D)         (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop1 (Dropout)              (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv3 (Conv2D)               (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "relu3 (Activation)           (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv4 (Conv2D)               (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "relu4 (Activation)           (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "maxp2 (MaxPooling2D)         (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                40970     \n",
            "=================================================================\n",
            "Total params: 106,538\n",
            "Trainable params: 106,538\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Lf0cFV6mEFhH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    samplewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    samplewise_std_normalization=False,\n",
        "    zca_whitening=False,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qe3-fk6PGyVT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2254
        },
        "outputId": "bb35d846-e090-4210-b5ca-08e688abf621"
      },
      "cell_type": "code",
      "source": [
        "tbCallBack =TrainValTensorBoard(log_dir='logs_keras_new/model_baseline_ep250', write_graph=True)\n",
        "datagen.fit(train_x)\n",
        "#training\n",
        "start = time.time()\n",
        "\n",
        "batch_size = 128\n",
        "epochs=250\n",
        "iterations = int(train_x.shape[0]/128)\n",
        "fit_history_base = model_base.fit_generator(datagen.flow(train_x, train_y, batch_size=batch_size),\n",
        "                                            steps_per_epoch=iterations,\n",
        "                                            epochs=epochs,\n",
        "                                            verbose=1,\n",
        "                                            validation_data=(valid_x,valid_y),\n",
        "                                            callbacks=[tbCallBack])\n",
        "                    \n",
        "model_base.save('model/model_baseline_ep250.h5')\n",
        "\n",
        "end = time.time()\n",
        "print(\"Model took %0.2f seconds to train\"%(end - start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "312/312 [==============================] - 27s 87ms/step - loss: 1.7830 - acc: 0.3569 - val_loss: 1.4201 - val_acc: 0.4915\n",
            "Epoch 2/250\n",
            "312/312 [==============================] - 25s 79ms/step - loss: 1.4710 - acc: 0.4742 - val_loss: 1.2967 - val_acc: 0.5456\n",
            "Epoch 3/250\n",
            "312/312 [==============================] - 25s 79ms/step - loss: 1.3508 - acc: 0.5258 - val_loss: 1.2081 - val_acc: 0.5863\n",
            "Epoch 4/250\n",
            "312/312 [==============================] - 25s 80ms/step - loss: 1.2663 - acc: 0.5567 - val_loss: 1.1025 - val_acc: 0.6192\n",
            "Epoch 5/250\n",
            "312/312 [==============================] - 25s 79ms/step - loss: 1.2036 - acc: 0.5808 - val_loss: 1.0203 - val_acc: 0.6553\n",
            "Epoch 6/250\n",
            "312/312 [==============================] - 25s 81ms/step - loss: 1.1535 - acc: 0.5998 - val_loss: 1.1351 - val_acc: 0.6183\n",
            "Epoch 7/250\n",
            "312/312 [==============================] - 25s 81ms/step - loss: 1.1037 - acc: 0.6199 - val_loss: 1.0058 - val_acc: 0.6557\n",
            "Epoch 8/250\n",
            "312/312 [==============================] - 25s 81ms/step - loss: 1.0721 - acc: 0.6325 - val_loss: 1.0195 - val_acc: 0.6550\n",
            "Epoch 9/250\n",
            "312/312 [==============================] - 25s 80ms/step - loss: 1.0392 - acc: 0.6455 - val_loss: 0.9283 - val_acc: 0.6899\n",
            "Epoch 10/250\n",
            "312/312 [==============================] - 25s 81ms/step - loss: 1.0237 - acc: 0.6502 - val_loss: 0.9030 - val_acc: 0.6991\n",
            "Epoch 11/250\n",
            "312/312 [==============================] - 25s 81ms/step - loss: 0.9963 - acc: 0.6603 - val_loss: 0.8310 - val_acc: 0.7254\n",
            "Epoch 12/250\n",
            "312/312 [==============================] - 25s 80ms/step - loss: 0.9708 - acc: 0.6713 - val_loss: 0.8817 - val_acc: 0.7133\n",
            "Epoch 13/250\n",
            "312/312 [==============================] - 25s 79ms/step - loss: 0.9513 - acc: 0.6774 - val_loss: 0.7928 - val_acc: 0.7408\n",
            "Epoch 14/250\n",
            "312/312 [==============================] - 24s 78ms/step - loss: 0.9381 - acc: 0.6818 - val_loss: 0.8615 - val_acc: 0.7146\n",
            "Epoch 15/250\n",
            "312/312 [==============================] - 25s 79ms/step - loss: 0.9283 - acc: 0.6866 - val_loss: 0.8215 - val_acc: 0.7326\n",
            "Epoch 16/250\n",
            "312/312 [==============================] - 24s 79ms/step - loss: 0.9074 - acc: 0.6948 - val_loss: 0.8470 - val_acc: 0.7271\n",
            "Epoch 17/250\n",
            "312/312 [==============================] - 25s 79ms/step - loss: 0.9034 - acc: 0.6979 - val_loss: 0.8116 - val_acc: 0.7381\n",
            "Epoch 18/250\n",
            "312/312 [==============================] - 24s 78ms/step - loss: 0.8876 - acc: 0.7022 - val_loss: 0.8756 - val_acc: 0.7142\n",
            "Epoch 19/250\n",
            "312/312 [==============================] - 25s 79ms/step - loss: 0.8812 - acc: 0.7037 - val_loss: 0.8262 - val_acc: 0.7323\n",
            "Epoch 20/250\n",
            "312/312 [==============================] - 25s 79ms/step - loss: 0.8757 - acc: 0.7065 - val_loss: 0.7948 - val_acc: 0.7484\n",
            "Epoch 21/250\n",
            "312/312 [==============================] - 25s 80ms/step - loss: 0.8595 - acc: 0.7138 - val_loss: 0.7878 - val_acc: 0.7446\n",
            "Epoch 22/250\n",
            "312/312 [==============================] - 24s 78ms/step - loss: 0.8600 - acc: 0.7124 - val_loss: 0.8103 - val_acc: 0.7439\n",
            "Epoch 23/250\n",
            "312/312 [==============================] - 25s 80ms/step - loss: 0.8542 - acc: 0.7167 - val_loss: 0.8211 - val_acc: 0.7385\n",
            "Epoch 24/250\n",
            "312/312 [==============================] - 24s 78ms/step - loss: 0.8450 - acc: 0.7193 - val_loss: 0.8290 - val_acc: 0.7375\n",
            "Epoch 25/250\n",
            "312/312 [==============================] - 25s 80ms/step - loss: 0.8323 - acc: 0.7250 - val_loss: 0.8793 - val_acc: 0.7235\n",
            "Epoch 26/250\n",
            "312/312 [==============================] - 25s 79ms/step - loss: 0.8375 - acc: 0.7238 - val_loss: 0.7827 - val_acc: 0.7528\n",
            "Epoch 27/250\n",
            "312/312 [==============================] - 25s 82ms/step - loss: 0.8220 - acc: 0.7280 - val_loss: 0.8944 - val_acc: 0.7210\n",
            "Epoch 28/250\n",
            "312/312 [==============================] - 25s 80ms/step - loss: 0.8208 - acc: 0.7311 - val_loss: 0.7826 - val_acc: 0.7573\n",
            "Epoch 29/250\n",
            "312/312 [==============================] - 25s 79ms/step - loss: 0.8173 - acc: 0.7333 - val_loss: 0.7904 - val_acc: 0.7522\n",
            "Epoch 30/250\n",
            "312/312 [==============================] - 25s 79ms/step - loss: 0.8111 - acc: 0.7293 - val_loss: 0.7984 - val_acc: 0.7531\n",
            "Epoch 31/250\n",
            "312/312 [==============================] - 24s 78ms/step - loss: 0.8138 - acc: 0.7317 - val_loss: 0.7243 - val_acc: 0.7715\n",
            "Epoch 32/250\n",
            "312/312 [==============================] - 25s 80ms/step - loss: 0.8023 - acc: 0.7356 - val_loss: 0.6850 - val_acc: 0.7855\n",
            "Epoch 33/250\n",
            "312/312 [==============================] - 24s 78ms/step - loss: 0.7987 - acc: 0.7384 - val_loss: 0.7602 - val_acc: 0.7623\n",
            "Epoch 34/250\n",
            "312/312 [==============================] - 24s 78ms/step - loss: 0.8086 - acc: 0.7349 - val_loss: 0.7934 - val_acc: 0.7509\n",
            "Epoch 35/250\n",
            "312/312 [==============================] - 25s 79ms/step - loss: 0.7878 - acc: 0.7430 - val_loss: 0.7842 - val_acc: 0.7571\n",
            "Epoch 36/250\n",
            "312/312 [==============================] - 25s 80ms/step - loss: 0.7862 - acc: 0.7410 - val_loss: 0.7225 - val_acc: 0.7755\n",
            "Epoch 37/250\n",
            "312/312 [==============================] - 25s 79ms/step - loss: 0.7836 - acc: 0.7441 - val_loss: 0.7622 - val_acc: 0.7666\n",
            "Epoch 38/250\n",
            "312/312 [==============================] - 25s 81ms/step - loss: 0.7902 - acc: 0.7419 - val_loss: 0.7619 - val_acc: 0.7632\n",
            "Epoch 39/250\n",
            "312/312 [==============================] - 25s 79ms/step - loss: 0.7790 - acc: 0.7474 - val_loss: 0.8175 - val_acc: 0.7534\n",
            "Epoch 40/250\n",
            "312/312 [==============================] - 26s 82ms/step - loss: 0.7801 - acc: 0.7433 - val_loss: 0.8027 - val_acc: 0.7500\n",
            "Epoch 41/250\n",
            "312/312 [==============================] - 25s 80ms/step - loss: 0.7767 - acc: 0.7459 - val_loss: 0.7665 - val_acc: 0.7681\n",
            "Epoch 42/250\n",
            "312/312 [==============================] - 25s 81ms/step - loss: 0.7764 - acc: 0.7476 - val_loss: 0.7653 - val_acc: 0.7681\n",
            "Epoch 43/250\n",
            "312/312 [==============================] - 25s 79ms/step - loss: 0.7695 - acc: 0.7509 - val_loss: 0.7809 - val_acc: 0.7635\n",
            "Epoch 44/250\n",
            "312/312 [==============================] - 26s 82ms/step - loss: 0.7770 - acc: 0.7439 - val_loss: 0.7748 - val_acc: 0.7643\n",
            "Epoch 45/250\n",
            "312/312 [==============================] - 25s 80ms/step - loss: 0.7627 - acc: 0.7517 - val_loss: 0.7159 - val_acc: 0.7806\n",
            "Epoch 46/250\n",
            "312/312 [==============================] - 25s 79ms/step - loss: 0.7624 - acc: 0.7519 - val_loss: 0.7827 - val_acc: 0.7590\n",
            "Epoch 47/250\n",
            "312/312 [==============================] - 25s 80ms/step - loss: 0.7597 - acc: 0.7541 - val_loss: 0.8046 - val_acc: 0.7556\n",
            "Epoch 48/250\n",
            "312/312 [==============================] - 25s 79ms/step - loss: 0.7646 - acc: 0.7517 - val_loss: 0.7441 - val_acc: 0.7716\n",
            "Epoch 49/250\n",
            "312/312 [==============================] - 25s 80ms/step - loss: 0.7579 - acc: 0.7555 - val_loss: 0.7042 - val_acc: 0.7816\n",
            "Epoch 50/250\n",
            "312/312 [==============================] - 25s 79ms/step - loss: 0.7543 - acc: 0.7544 - val_loss: 0.7476 - val_acc: 0.7687\n",
            "Epoch 51/250\n",
            "312/312 [==============================] - 25s 81ms/step - loss: 0.7564 - acc: 0.7534 - val_loss: 0.7721 - val_acc: 0.7690\n",
            "Epoch 52/250\n",
            "312/312 [==============================] - 25s 79ms/step - loss: 0.7573 - acc: 0.7521 - val_loss: 0.7846 - val_acc: 0.7622\n",
            "Epoch 53/250\n",
            "312/312 [==============================] - 25s 80ms/step - loss: 0.7471 - acc: 0.7571 - val_loss: 0.7627 - val_acc: 0.7702\n",
            "Epoch 54/250\n",
            "312/312 [==============================] - 25s 79ms/step - loss: 0.7459 - acc: 0.7588 - val_loss: 0.6955 - val_acc: 0.7830\n",
            "Epoch 55/250\n",
            "312/312 [==============================] - 25s 81ms/step - loss: 0.7447 - acc: 0.7597 - val_loss: 0.7041 - val_acc: 0.7835\n",
            "Epoch 56/250\n",
            "312/312 [==============================] - 25s 79ms/step - loss: 0.7456 - acc: 0.7566 - val_loss: 0.7609 - val_acc: 0.7685\n",
            "Epoch 57/250\n",
            "312/312 [==============================] - 26s 82ms/step - loss: 0.7451 - acc: 0.7603 - val_loss: 0.7283 - val_acc: 0.7771\n",
            "Epoch 58/250\n",
            "312/312 [==============================] - 25s 80ms/step - loss: 0.7445 - acc: 0.7578 - val_loss: 0.7912 - val_acc: 0.7603\n",
            "Epoch 59/250\n",
            "312/312 [==============================] - 25s 80ms/step - loss: 0.7434 - acc: 0.7597 - val_loss: 0.7558 - val_acc: 0.7742\n",
            "Epoch 60/250\n",
            "312/312 [==============================] - 25s 81ms/step - loss: 0.7388 - acc: 0.7621 - val_loss: 0.6903 - val_acc: 0.7914\n",
            "Epoch 61/250\n",
            "312/312 [==============================] - 25s 79ms/step - loss: 0.7425 - acc: 0.7595 - val_loss: 0.7551 - val_acc: 0.7715\n",
            "Epoch 62/250\n",
            "312/312 [==============================] - 25s 80ms/step - loss: 0.7268 - acc: 0.7656 - val_loss: 0.8211 - val_acc: 0.7563\n",
            "Epoch 63/250\n",
            "203/312 [==================>...........] - ETA: 8s - loss: 0.7421 - acc: 0.7619"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C_8Y6CVBI0MB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# weight decay"
      ]
    },
    {
      "metadata": {
        "id": "HJt-cdQmI1_m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_model_decay(num_classes = 10, baseMapNum = 32, weight_decay = 1e-4):\n",
        "    '''build weight decay model'''\n",
        "    model_decay = Sequential()\n",
        "    model_decay.add(Conv2D(baseMapNum, (3,3), name='conv1', padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=train_x.shape[1:]))\n",
        "    model_decay.add(Activation('relu', name='relu1'))\n",
        "    model_decay.add(BatchNormalization(name='batchn1'))\n",
        "    model_decay.add(Conv2D(baseMapNum, (3,3), name='conv2', padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model_decay.add(Activation('relu', name='relu2'))\n",
        "    model_decay.add(BatchNormalization(name='batchn2'))\n",
        "    model_decay.add(MaxPooling2D(pool_size=(2,2), name='maxp1'))\n",
        "    model_decay.add(Dropout(0.2, name='drop1'))\n",
        "\n",
        "    model_decay.add(Conv2D(2*baseMapNum, (3,3), name='conv3', padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model_decay.add(Activation('relu', name='relu3'))\n",
        "    model_decay.add(BatchNormalization(name='batchn3'))\n",
        "    model_decay.add(Conv2D(2*baseMapNum, (3,3), name='conv4', padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model_decay.add(Activation('relu', name='relu4'))\n",
        "    model_decay.add(BatchNormalization(name='batchn4'))\n",
        "    model_decay.add(MaxPooling2D(pool_size=(2,2), name='maxp2'))\n",
        "    model_decay.add(Dropout(0.3, name='drop1'))\n",
        "\n",
        "    model_decay.add(Conv2D(4*baseMapNum, (3,3), name='conv5', padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model_decay.add(Activation('relu', name='relu5'))\n",
        "    model_decay.add(BatchNormalization(name='batchn5'))\n",
        "    model_decay.add(Conv2D(4*baseMapNum, (3,3), name='conv6', padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model_decay.add(Activation('relu', name='relu6'))\n",
        "    model_decay.add(BatchNormalization(name='batchn6'))\n",
        "    model_decay.add(MaxPooling2D(pool_size=(2,2), name='maxp3'))\n",
        "    model_decay.add(Dropout(0.4, name='drop1'))\n",
        "\n",
        "    model_decay.add(Flatten())\n",
        "    model_decay.add(Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "    opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
        "    model_decay.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n",
        "    \n",
        "    return model_decay\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nfzpU8tuI59M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_decay = build_model_decay()\n",
        "print(model_decay.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NaZtBcf6cJQr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "150 epochs"
      ]
    },
    {
      "metadata": {
        "id": "Th8SqSFgK3MM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tbCallBack =TrainValTensorBoard(log_dir='logs_keras_new/model_weight_decay_ep150',write_graph=True)\n",
        "datagen.fit(train_x)\n",
        "\n",
        "#training\n",
        "start = time.time()\n",
        "\n",
        "batch_size = 128\n",
        "epochs=150\n",
        "iterations = int(train_x.shape[0]/128)\n",
        "steps_per_epoch=iterations\n",
        "fit_history_decay150 = model_decay.fit_generator(datagen.flow(train_x, train_y, batch_size=batch_size),\n",
        "                                         steps_per_epoch=iterations,\n",
        "                                         epochs=epochs,\n",
        "                                         verbose=1,\n",
        "                                         validation_data=(valid_x,valid_y),\n",
        "                                         callbacks=[tbCallBack])\n",
        "model_decay.save('model/model_weight_decay_ep150.h5')\n",
        "\n",
        "end = time.time()\n",
        "print(\"Model took %0.2f seconds to train\"%(end - start))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hZFY9v5tSRAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "22eceae5-6ed4-4710-85b3-edaf4865eda1"
      },
      "cell_type": "code",
      "source": [
        "# plot_model_history(fit_history1)\n",
        "eva_result = model_decay.evaluate(test_x, test_y, batch_size=128, verbose=1)\n",
        "acc = eva_result[1]; loss = eva_result[0]\n",
        "print('\\nTest result: %.3f loss: %.3f' % (acc*100, loss))\n",
        "\n",
        "# model_decay_test = load_model('model/model_weight_decay_test.h5')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 156us/step\n",
            "\n",
            "Test result: 75.850 loss: 0.841\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_2NprnDSTn1Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_prob = model_decay_test.predict(test_x) \n",
        "y_pred = y_prob.argmax(axis=-1)\n",
        "y_true = np.where(test_y == 1)[1]\n",
        "cm = confusion_matrix(y_true, y_pred, labels = range(10))\n",
        "df_cm = pd.DataFrame(cm, index = [i for i in labels],\n",
        "                     columns = [i for i in labels])\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm, annot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "USiF8HmPcES_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "250 epochs"
      ]
    },
    {
      "metadata": {
        "id": "2200Q1n9cCKm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_decay = build_model_decay()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yGn7J-Jhb8vk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tbCallBack =TrainValTensorBoard(log_dir='logs_keras_new/model_weight_decay_ep250',write_graph=True)\n",
        "datagen.fit(train_x)\n",
        "\n",
        "#training\n",
        "start = time.time()\n",
        "\n",
        "batch_size = 128\n",
        "epochs=250\n",
        "iterations = int(train_x.shape[0]/128)\n",
        "steps_per_epoch=iterations\n",
        "fit_history_decay_250 = model_decay.fit_generator(datagen.flow(train_x, train_y, batch_size=batch_size),\n",
        "                                         steps_per_epoch=iterations,\n",
        "                                         epochs=epochs,\n",
        "                                         verbose=1,\n",
        "                                         validation_data=(valid_x,valid_y),\n",
        "                                         callbacks=[tbCallBack])\n",
        "model_decay.save('model/model_weight_decay_ep250.h5')\n",
        "\n",
        "end = time.time()\n",
        "print(\"Model took %0.2f seconds to train\"%(end - start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OhhFRKx0TQWz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# NIN"
      ]
    },
    {
      "metadata": {
        "id": "1KJYeF0kTPl2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_model_NIN(train_x, num_classes = 10, baseMapNum = 32, weight_decay = 1e-4):\n",
        "    '''build NIN model: \n",
        "       1.convolution layer followed by 2 1*1 convlution layer(mlp)\n",
        "       2.end with 10 filters mlp, averagepooling, softmax\n",
        "    '''\n",
        "    model= Sequential()\n",
        "    model.add(Conv2D(baseMapNum*3, (5,5), name='conv1', padding = 'same', kernel_regularizer=regularizers.l2(0.0001), input_shape=train_x.shape[1:]))\n",
        "    model.add(Activation('relu', name='relu1'))\n",
        "    model.add(Conv2D(baseMapNum*2, (1,1), name='mlp1', padding = 'same', kernel_regularizer=regularizers.l2(0.0001)))\n",
        "    model.add(Activation('relu', name='relu2'))\n",
        "    model.add(Conv2D(baseMapNum*2, (1,1), name='mlp2', padding = 'same', kernel_regularizer=regularizers.l2(0.0001)))\n",
        "    model.add(Activation('relu', name='relu3'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='maxp1'))\n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    model.add(Conv2D(baseMapNum*3, (3,3), name='conv2', padding = 'same', kernel_regularizer=regularizers.l2(0.0001)))\n",
        "    model.add(Activation('relu', name='relu4'))\n",
        "    model.add(Conv2D(baseMapNum*2, (1,1), name='mlp3', padding = 'same', kernel_regularizer=regularizers.l2(0.0001)))\n",
        "    model.add(Activation('relu', name='relu5'))\n",
        "    model.add(Conv2D(baseMapNum*2, (1,1), name='mlp4', padding = 'same', kernel_regularizer=regularizers.l2(0.0001)))\n",
        "    model.add(Activation('relu', name='relu6'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='maxp2'))\n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    model.add(Conv2D(baseMapNum*2, (3,3), name='conv3', padding = 'same', kernel_regularizer=regularizers.l2(0.0001)))\n",
        "    model.add(Activation('relu', name='relu7'))\n",
        "    model.add(Conv2D(baseMapNum, (1,1), name='mlp5', padding = 'same', kernel_regularizer=regularizers.l2(0.0001)))\n",
        "    model.add(Activation('relu', name='relu8'))\n",
        "    model.add(Conv2D(num_classes, (1,1), name='mlp6', padding = 'same', kernel_regularizer=regularizers.l2(0.0001)))\n",
        "    model.add(Activation('relu', name='relu9'))\n",
        "    model.add(AveragePooling2D(pool_size=(2, 2), name='maxp3'))\n",
        "    \n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) \n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FeFNtL6ygycj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NIN = build_model_NIN()\n",
        "print(NIN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kxlX_U0-gKFV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tbCallBack =TrainValTensorBoard(log_dir='logs_keras_new/model_NIN_ep150',write_graph=True)\n",
        "datagen.fit(train_x)\n",
        "\n",
        "#training\n",
        "start = time.time()\n",
        "\n",
        "batch_size = 128\n",
        "epochs=150\n",
        "iterations = int(train_x.shape[0]/128)\n",
        "steps_per_epoch=iterations\n",
        "fit_history_nin_150 = NIN.fit_generator(datagen.flow(train_x, train_y, batch_size=batch_size),\n",
        "                                         steps_per_epoch=iterations,\n",
        "                                         epochs=epochs,\n",
        "                                         verbose=1,\n",
        "                                         validation_data=(valid_x,valid_y),\n",
        "                                         callbacks=[tbCallBack])\n",
        "NIN.save('model/model_nin_ep150.h5')\n",
        "\n",
        "end = time.time()\n",
        "print(\"Model took %0.2f seconds to train\"%(end - start))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pwuk2NpjgcsT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NIN = build_model_NIN()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l-jjkUGNg6R1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tbCallBack =TrainValTensorBoard(log_dir='logs_keras_new/model_NIN_ep250',write_graph=True)\n",
        "datagen.fit(train_x)\n",
        "\n",
        "#training\n",
        "start = time.time()\n",
        "\n",
        "batch_size = 128\n",
        "epochs=250\n",
        "iterations = int(train_x.shape[0]/128)\n",
        "steps_per_epoch=iterations\n",
        "fit_history_nin_250 = NIN.fit_generator(datagen.flow(train_x, train_y, batch_size=batch_size),\n",
        "                                         steps_per_epoch=iterations,\n",
        "                                         epochs=epochs,\n",
        "                                         verbose=1,\n",
        "                                         validation_data=(valid_x,valid_y),\n",
        "                                         callbacks=[tbCallBack])\n",
        "NIN.save('model/model_nin_ep250.h5')\n",
        "\n",
        "end = time.time()\n",
        "print(\"Model took %0.2f seconds to train\"%(end - start))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}